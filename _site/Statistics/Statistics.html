<!DOCTYPE html>
<html lang="en-US">

    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
          MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['\$','\$'], ["\\(","\\)"] ],
          },

      });
    </script>

 
  <head>

    

      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141212522-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-141212522-1');
      </script>

    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Prelude: Statistics | IT Taolu</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="The Prelude: Statistics" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Read best Taolus of IT industry" />
<meta property="og:description" content="Read best Taolus of IT industry" />
<link rel="canonical" href="http://localhost:4000/Statistics/Statistics.html" />
<meta property="og:url" content="http://localhost:4000/Statistics/Statistics.html" />
<meta property="og:site_name" content="IT Taolu" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Prelude: Statistics" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Read best Taolus of IT industry","headline":"The Prelude: Statistics","url":"http://localhost:4000/Statistics/Statistics.html"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=4cab4a74ddc0c244cdb3a9379be74bd111eeaa7b">
  </head>
  <body>
    <header class="page-header" role="banner">
      <h1 class="project-name">IT Taolu</h1>
      <h2 class="project-tagline">Read best Taolus of IT industry</h2>
      
        <a href="https://github.com/wylswz/wylswz.github.io" class="btn">View on GayHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="the-prelude-statistics">The Prelude: Statistics</h1>
<p>Before getting into real statistical machine learning, I’ll have to recap some basic statistics basic stuff… The main objective is to give a intuitive explanation of those basic concepts that are required in machine learning.</p>

<p>As we know, statistics has two branches, descriptive and inferential. The descriptive statistics is used to represent a bunch of data while inferential statistics uses data to make conclusion about things. Both of them are covered in statistical machine learning, and a large part of that is <strong>probability theory</strong>, where we are going to start.</p>

<h2 id="random-process">Random Process</h2>

<h3 id="random-variables">Random Variables</h3>
<p>A variable is something whose value may change, but random variable seem to be a little bit tricky, because it can taken on a bunch of different values at the same time, and we can never solve it for its value. However, we can develop something to describe how does it work.</p>

<p>A random variable can be treated as a map from a random process to a number, which is random. For example, we have a random variable which represents whether it rains tomorrow. It is 1 if it rains tomorrow, otherwise 0.</p>

\[X=
\begin{cases}
    1 &amp; \text{rain tomorrow} \\
    0 &amp; \text{no rain}
\end{cases}\]

<p>In order to describe the behavior of random variable, we have a probability assigned to it</p>

\[P(X=x_1)\]

<p>The expression above indicates the probability for $X$ to have the value $x_1$.</p>

<p>Random variables can be either discrete or continuous.</p>

<h3 id="binomial-distribution">Binomial Distribution</h3>
<p>The core of Binomial Distribution is doing a series of random experiments, each of that has exactly two possible outcomes. For example, we are flipping a fair coin for $5$ times and let random variable $X$ represent the number of heads occurred after $5$ flips, so $X$ can be $0$, $1$, $2$, $3$, $4$, or $5$. We can calculate the probability for first three cases and the other 3 cases are symmetric.</p>

\[P(X=0) = (\frac{1}{2})^5\]

\[P(X=1) = {5 \choose 1}\times(\frac{1}{2})^5\]

\[P(X=2) = {5 \choose 2}\times(\frac{1}{2})^5\]

<p>This is quite intuitive, we have probability of $(\frac{1}{2})^5$ for each possible combination of 5 coins, and in order to calculate the probability of $k$ heads, we are actually choosing $k$ coins from $5$ and let them to be head.</p>

<p>Now let’s make the problem a little bit complex. Suppose we have unfair coins, which has probability of $0.3$ to be head. In this case</p>

\[P(X=0) = 0.3^5\]

\[P(X=1) = {6 \choose 1} \times 0.3 \times 0.7^4\]

<p>The calculation becomes</p>
<ul>
  <li>Select $k$ fron $N$ to represent head</li>
  <li>multiply by probability of head to the power of $k$</li>
  <li>multiply by probability of tail to the power of $(N-k)$</li>
</ul>

<p>The expectation of binomial distribution is 
\(E(X) = np\)</p>

<p>where $n$ is the number of experiments and $p$ is the probability of succeed one time. Let’s prove that. We know that</p>

\[P(X=k) = {n \choose k}p^k(1-p)^{n-k}\]

<p>and the expection is the probabilistic weighted sum of outcomes</p>

\[\begin{aligned}
    E(X) &amp; = \sum_{k=0}^{n}{n \choose k}p^k(1-p)^{n-k} \\
    &amp; = \sum_{k=0}^n\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k} \\
    &amp; = \sum_{k=1}^n\frac{n(n-1)!}{(k-1)!(n-k)!}p\cdot p^{k-1} (1-p)^{n-k} \\
    &amp; = np \cdot \sum_{k=1}^{n}\frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1} (1-p)^{n-k}
\end{aligned}\]

<p>The part after $np$ in the equation above is actually the sum of probability of getting $k-1$ successes in $n-1$ trials with probability of each trail to be $p$. The sum should be $1$, so expected value is $np$</p>

<h3 id="poisson-process">Poisson Process</h3>
<p>You might find Poisson process quite tricky, just like I did, because the math teacher sucks. Think about this scenario, we want to look at <em>how many vehicles pass the crossroad in one hour</em>. So we have random variable $X = #\text{cars pass in 1 h}$, and we have following assumptions</p>
<ul>
  <li>Every hour is identical</li>
  <li>Hours are independent</li>
</ul>

<p>How are we gonna solve this? Well, let’s assume that this problem is bionomial, that is, we divide one hour into 60 minutes, and do one trial per minute, there can either be one car passing by or no car at all. So we have</p>

<p>\(E(X) = np = \lambda\)
where $\lambda$ is the number of cars per 60 minutes. So for each minute, the probability of having a car passing by is $\frac{\lambda}{60}$, so using the conclusion from binomial distribution, we have</p>

\[P(X=k) = {60 \choose k}(\frac{\lambda}{60})^k(1-\frac{\lambda}{60})^{60-k}\]

<p>But the problem is that there might be multiple cars passing by in one minute, which means we need a finer grained approximation. Well, the idea is to divide one hour into more intervals (infinite intervals).</p>

<p>Before we get into that, let’s look at couple of facts that is helpful later on.</p>

<!-- \lim_{x\rightarrow\infty} -->

<p>\(\lim_{x\rightarrow\infty} (1+\frac{a}{x})^x = e^a\)
It is quite straightforward to get this, simply let 
\(\frac{x}{a} = n\)
Then the equation becomes 
\(\lim_{n\rightarrow\infty} ((1+\frac{1}{n})^n)^a = e^a\)</p>

\[\frac{x!}{(x-k)!} = x(x-1)(x-2)...(x-k+1)\]

<p>Our probability is written as</p>

\[\begin{aligned}
    P(X=k) &amp; = \lim_{n\rightarrow\infty} {n\choose k}(\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^{n-k} \\
    &amp; = \lim_{n\rightarrow\infty} \frac{n!}{k!(n-k)!}(\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^n(1-\frac{\lambda}{n})^{-k}\\

    &amp;=\lim_{n\rightarrow\infty}\frac{1}{k!}n(n-1)...(n-k+1)e^{-\lambda}(\frac{\lambda}{n})^k \\
    &amp;= \lim_{n\rightarrow\infty}\frac{1}{k!}\frac{\lambda^k(n^k + ...)}{n^k}e^{-\lambda}\\
    &amp;= \frac{\lambda^k}{k!}e^{-\lambda }
\end{aligned}\]

<h3 id="bernoulli-distribution">Bernoulli Distribution</h3>
<p>Bernoulli is a special case of Binomial distribution with one single trial. For example, we have a random variable $X$ which represents the result of flipping a coin, which can either be Head or Tail.</p>

\[x = 
\begin{cases}
1 &amp; Head\\
0 &amp; Tail

\end{cases}\]

<p>Then the pdf of the distribution is simply</p>

<p>\(P(X) = p^k(1-p)^{1-k}\)
where $k$ can either be $0$ or $1$.</p>

<h3 id="beta-distribution">Beta distribution</h3>
<p>The probability distribution of beta distribution is simply given by</p>

\[Beta(a,b) = \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}\]

\[B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\]

<p>where $\theta$ is a random variable of which the value is from $0$ to $1$. The demoninator is a normalization function of $a$ and $b$ in order to make sure the integration of pdf over random variable is 1.</p>

<p>The following graph indicates different pdf shapes when $a$ and $b$ have different value combinations.</p>

<p><img src="/Statistics/img/beta.png" alt="" /></p>

<h3 id="frequentist-approach-vs-bayesian-approach">Frequentist Approach vs Bayesian Approach</h3>
<p>The difference between frequentist and Bayesian approach is that the assumption of variation of data and parameter. The frequentist assumes that the parameters are fixed in a certain problem, for example, in flipping coin trial, the parameter $p$ which represents the probability of Head is always 0.5. The infrerences are done by applying mathematics to the fixed parameters directly.</p>

<p>While the bayesian approach assumes that the data is fixed and the parameters can vary. In the case of flipping a coin, the probability of having a Head may related to some priors, for example, the gravity, the angle of the coin… As long as these parameters are fixed, we will always have same result. The uncertainty is introduced by the initial condition.</p>

<h3 id="bayes-rule">Bayes’ rule</h3>
<p>The Bayes’ rule states the the posterior of parameter of a given distribution is given by
\(P(\theta|x) = \frac{P(x|\theta)P(\theta)}{P(x)}\)</p>

<table>
  <tbody>
    <tr>
      <td>where the $P(x</td>
      <td>\theta)$ is the likelihood and $P(\theta)$ is the prior distribution. Because of the assumption of certainty of invarient data, the posterior is proportional to likelihood multiplied by the prior</td>
    </tr>
  </tbody>
</table>

\[P(\theta|x) \propto P(\theta)P(x|\theta)\]

<p>This relationship is quite useful if we assume the prior to be uniformly distributed, because we can maximize the posterior by maximizing the likelihood.</p>

<h3 id="likelihood-isnt-a-distribution">Likelihood isn’t a distribution</h3>
<p>The likelihood $P(x|\theta)$ can also be written as $L(\theta|x)$.
We can figure out that
\(\int L(\theta|x) dx = 1\)
but in bayesian approach, the data is fixed, and the parameters are variables. If we integrate the likelihood 
\(\int P(x|\theta) d\theta\)</p>

<p>we are actually summing up the probability of data given parameter for all possible parameters. If the $\theta$ is from $-\infty$ to $\infty$, the integral can potentially be $-\infty$ to $\infty$, which does not satisfy the property of a distribution. That’s why we always say likelihood function instead of likelihood distribution.</p>

<h3 id="conjugate-distribution">Conjugate Distribution</h3>
<p>If prior and posterior distributions are of the same probability distribution family, and the prior is called the conjugate prior to the likelihood function.</p>

<p>For example, Beta distribution is conjugate to Bernoulli/Binomial distribution. In order to understand this, we’ll need to introduce the Gamma function. Gamma function is like factorial defined on Real numbers. For an non-negative integer $\alpha$, we have</p>

\[\Gamma(\alpha + 1) = \alpha!\]

<p>Therefore, we can write choose function into the form of Gamma function</p>

\[{N \choose x} = \frac{\Gamma(N+1)}{\Gamma(N-x+1)\Gamma(x+1)}\]

<p>Now we have a posterior distribution
\(P(\theta|x) \propto P(x|\theta)P(\theta)\)</p>

<p>where
\(P(\theta) \sim Beta(a,b)\)</p>

<p>From Binomial distribution, we have
\(P(x|\theta) \propto \theta^z(1-\theta)^{N-z}\)</p>

<p>and from Beta distribution we have 
\(P(\theta) \propto \theta^{a-1}(1-\theta)^{b-1}\)</p>

<p>let $a’ = a + z$ and $b’ = N+b-z$, we can simply get</p>

\[P(\theta|x) \sim Beta(a', b')\]

<h1 id="machine-learning-basics">Machine Learning Basics</h1>

<h2 id="regression-as-probabilistic-model">Regression as Probabilistic Model</h2>
<h3 id="linear-regression-with-gaussian-noise">Linear Regression with Gaussian Noise</h3>
<p>Suppose that we have a linear model with Gaussian noise, given by</p>

\[Y =\bold{X'w} + \sigma\]

<p>\(\sigma \sim \mathcal{N}(0, \sigma^2)\)
with
\(\mathcal{N}(x;\mu \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(x-\mu)^2}{2\sigma^2})\)</p>

<p>Combining the linear and Gaussian distribution, we get the equivalent posterior</p>

\[P(y|x) \sim \mathcal{N}(\bold{X'w},\sigma^2)\]

\[P(y|x) = \frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{(y-wx)^2}{2\sigma^2})\]

<p>The posterior of parameter $w$ is proportional to 
\(P(y|x) = \prod P(y_i|x_i)\)</p>

<p>Taking logarithm, we have</p>

\[\begin{aligned}
    LL(w) &amp; = \sum log(P(y_i|x_i))\\
    &amp;=\sum -\frac{1}{2\sigma^2}(y-wx)^2 +C
\end{aligned}\]

<p>It is quite obvious that the log-likelihood of parameter $w$ is proportional to the sum of square loss.</p>
<h2 id="logistic-regression">Logistic Regression</h2>

<h2 id="perceptron-learning-algorithm">Perceptron Learning Algorithm</h2>

<h2 id="multi-layer-perceptron-and-back-propagation">Multi-layer perceptron and back propagation</h2>

<h2 id="svm-and-kernel-method">SVM and Kernel Method</h2>
<p>Support vector machine is a binary classification tool. It takes a data point and output a value which is $1$ or $-1$.
What we wanna do with SVM is that we wanna find the support vectors that are closest data instances to the hyperplain that divide the dataset, and find such a hyperplain that maximize the distance.</p>

<h3 id="hard-margin-svm">Hard margin SVM</h3>

<p>Suppose if we have a data point $X$, the distance between the point and the hyper plain $P:y = w’x + b$ is calculated as follows:</p>
<ul>
  <li>We find a vector $r$, which is $X + r = X_p$, where $X_p$ is a point on the hyper plain and $r\perp P$</li>
  <li>It is obvious that $r$ is parallel to $w$</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>The magnitude of $r$ is given by $r=w\frac{</td>
          <td> </td>
          <td>r</td>
          <td> </td>
          <td>}{</td>
          <td> </td>
          <td>w</td>
          <td> </td>
          <td>}$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>We have $X + w\frac{</td>
          <td> </td>
          <td>r</td>
          <td> </td>
          <td>}{</td>
          <td> </td>
          <td>w</td>
          <td> </td>
          <td>} = X_p$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Multiply $w$ on both sides and add $b$, and we know $X_p$ is on hyper plain, so we finally get $</td>
          <td> </td>
          <td>r</td>
          <td> </td>
          <td>= \plusmn \frac{w’x + b}{</td>
          <td> </td>
          <td>w</td>
          <td> </td>
          <td>}$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Because the $y$ is either $-1$ or $1$, we get $</td>
          <td> </td>
          <td>r</td>
          <td> </td>
          <td>= \frac{y_i(w’x + b)}{</td>
          <td> </td>
          <td>w</td>
          <td> </td>
          <td>}$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p>The SVM maxinizes the magnitude of $r$</p>

<table>
  <tbody>
    <tr>
      <td>$\max \frac{y_i(w’x + b)}{</td>
      <td> </td>
      <td>w</td>
      <td> </td>
      <td>}, i=1,2,…n$</td>
    </tr>
  </tbody>
</table>

<p>The problem is that there might be infinity possible values for $w$ and $b$ which are $\alpha w$ and $\alpha b$ where $\alpha&gt;0$. In order to resolve the ambiguity, we have following constraints</p>

<p>\(\frac{y_{i*}(w'x_{i*} + b)}{||w||} = \frac{1}{||w||}\)
where $*$ denotess the closest data point to the hyper-plain. Than the objective becomes 
\(\argmin_{w,b} ||w|| \\
s.t. \text{  } y_i(w'x + b) \geq 1\)</p>

<h3 id="training-hard-margin-svm">Training hard margin SVM</h3>
<p>To train the hard margin SVM, we need to apply Lagrangian Duality. The canonical form of it is show as following</p>

\[\argmin f(x) \\
s.t \text{ } g(x) \leq 0,\\
h(x) = 0\]

<p>And we have following exoression introducing some auxilliary variable $\lambda$ and $\nu$</p>

\[L(x, \lambda, \nu) = f(x) + \sum \lambda_i g_i(x) + \sum \nu_j h_j(x)\]

<p>For hard margin SVM, the lagrange multiplier is shown as follows</p>

\[L = \frac{1}{2}||w||^2 - \sum \lambda (y(w'x + b) - 1)\]

<p>We have $\frac{\delta L}{\delta b} = \sum \lambda y = 0$ and $\frac{\delta L}{\delta w} = w - \sum_i\lambda_iy_ix_i = 0$</p>

<p>Substituting into the original expression, we get 
\(L' = \sum_i\lambda_i - \frac{1}{2}\sum_i\sum_j \lambda_i\lambda_jy_iy_jx_ix_j\)
Where the $L’$ is the dual problem of prime problem. In order to predict, just calculate the sing
\(s = b + \sum \lambda_iy_ix_ix_j\)
where $x_j$ is the point to predict.</p>

<h2 id="bayesian-network">Bayesian Network</h2>

<h3 id="discrete-variable-joint-probability-distribution">Discrete variable joint probability distribution</h3>
<p>When we do inferences like</p>

<p>\(P(x|\vec{e})\)
where $\vec{e}$ is the evidence or observed variables, 
it’s quite straightforward to think of bayes’ theorem</p>

\[P(x|\vec{e}) = \frac{P(x, \vec{e})}{P(\vec{e})} = \frac{1}{Z}P(x,\vec{e})\]

<p>But there might be other variables that are neigher $x$ nor $\vec{e}$, which are called $H$, they can be marginalized out like this</p>

\[P(x|\vec{e}) = \frac{1}{Z}\sum_H P(x,\vec{e},H)\]

<p>then the posterior is related to the full joint probability distribution.</p>

<p>Bayesian network is good at helping reducing the number of parameters required to calculate the joint probability by assuming dependancies between random variables. For example the figure below:</p>

<p><img src="/Statistics/img/bayesnet.png" alt="" /></p>

<p>Where $A$ $B$ $C$ $D$ $E$ are random variables with two possible values: $1$ and $0$</p>

<p>if we write down the joint probability ignoring the graph,
\(P(A,B,C,D,E)\)
needs $2^5$ parameters because we need the value of probability when those 5 random variables take each of 2 possible values.</p>

<p>After taking the graph into consideration, the dependencies actually changed. For example, the random variable $A$ and $B$ doesn’t have any parents. The joint distribution then becomes</p>

\[P(A,B,C,D,E) = P(A)P(B)P(C|A,B)P(E|C,D)P(D|C,B)\]

<p>the number of parameters becomes</p>

<p>\(1+1+4+4+4 = 14\)
which is much less than previous one. In fact the growth of parameters follows $O(nd^k)$ where $d$ is possible values of random variables, $k$ is number of parents on average and $n$ is the number of nodes.</p>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/wylswz/wylswz.github.io">wylswz.github.io</a> is maintained by <a href="https://github.com/wylswz">wylswz</a>.</span>
        
      </footer>
    </main>
  </body>
  <script>

</script>
</html>

