# Face Recognition Development Notes

## Tensorflow

### Graph
Tensorflow is a graph-based computation framework. Using graph provides better readibality, parallelism and optimization of pre-compiling.


In declarative programming, the outputs of functions are independent of external states, instead, they only depend on the inputs, which eliminates most troubles caused by the side effect. In tensorflow, each function or operation is a single node in the graph.

The Graph characteristic of tensorflow also provide the capability of pre-compiling. Instead of executing the codes line by line like interpreted language (Python say for example), a graph is generated by pre-compiling the code. Optimization like parallelize independent logics, removal of useless logics and extracion of shared logics are available, thus make it more efficient.

### Key elements in tensorflow graph





## Model design

The primary problem of the project is to find selfie among the photos uploaded by twitter users. This problem can be treat as an object detection problem. However, the challenge part is that we can only refer to user's avatar as how does the user look like. Therefore, it is impossible to train a netowork to classify a photo as sombody. Moreover, we want the model to be generalized so it can detect users that have never be seen before, therfore training the network using user-id as class is infeasible in this case.

Instead of detecting user directly, we introduce two separated steps to accomplish this task. The first one is to detect the object using RCNN-like networks or YOLO(You only look once). The second step is to compare the detected face to the face in user's avatar, using one-shot algorithm like Siamese Net.

### Dataset

The [dataset](http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/) is a collection of loosely cropped human faces. The filename structure is in the form of "n{id}/{filename}.jpg". The photos of the same person are placed under the same directory.


### RCNN
RCNN is on of the simplest way of object detection. It works as follows:

- Pre-process the input image to a certain size (Cropping or wrapping)
- Select some regions using region proposal algorithms based on the features of the image like edges, colors, etc... Typically 1000 to 2000 regions proposed for each image
- For each region, run CNN to extract the feature
- Use SVM to classify the object
- Output class + bounding box

Advantage: Very simple

Disadvantage: Repeated CNN make it very slow, high computation waste.

### Fast RCNN
Fast RCNN improve the efficiency by following changes.

- Running convolution on the image for only once at the beginning
- Proposed regions are mapped to the output of convolution net directly instread of run convnet on original regions.
- Using convolution implementation for fully connected layer.


### Faster RCNN
Faster RCNN makes it even faster by proposing bounding boxes using pre-trained neural networks.

#### YOLO
YOLO is even faster than faster-RCNN but it has trade accuracy off for speed to make real-time detection in video stream possible.

The main idea of YOLO is dividing the image into grids, say 7 by 7 grids. Each grid cell predicts B bounding boxes and corresponding confidence.

In prediction session, the model infers the class-wise confidence of each grid cell. This indicates how well the object belongs to a class and how well the object is fitted. 

The limitation of YOLO is that when there are overlapping between objects or multiple objects appear in the same box, it can hardly operate well.

### NN shit

#### Gradient descend

#### Regularization

#### Optimizers

### CNN

#### Convolution

#### Pooling

#### Fully connect

#### Convolution implementation of fully connect 

## Designing


### Model and estimator
Estimator is high-level API of tensorflow which helps simplifying building machine learning models. It encapsulates four different operations (available in tf.estimator.ModeKeys):

- Training
- Prediction
- Evaluation
- Export for serving

To use estimator, we have the define following modules:

- **Model function** which includes the internal logic of the model, like layers, loss functions and optimizations. It accept following parameters:
  - feature (Fed by input function)
  - label (Fed by input function)
  - mode (instance of tf.estimator.ModeKey)
  - params (Other parameters)

- **Input function** This function feeds data into the model function, act like feed_dict for placeholder in old style APIs. It usually return an Iterator.get_next() which yield the next item of the iterator each time it is evaluated in the session. A recommended implementation is to directly return a tf.data.Dataset instance. The dataset can be pre processed using dataset.map with parse function. For example, it the dataset is a collection of image url, the parse function maps the url to actual image.

### Data streamer
In this project, the dataset is in the form of a large image collection, which is sometimes tens or hundreds Gigabytes in size. In this case, we can hardly fit the training dataset into memory, therefore we have to build a pipeline for data streaming. Pipeline does not only help streaming smaller batches of data, but also balance the load between CPU and GPU. The CPU can be used to pre-process and stream the data online, while GPU is in charge of running convolutions and weight updating.

As mentioned before, the dataset is stored in the file system of host, so all we need to do is to build a generator which keeps yielding the path of image files. A very simple version can be built as following:

```python

def file_dir_streamer(image_dir):
    file_list = os.walk(image_dir)
    # root, dir, files
    file_dic = {}
    for r in file_list:
        file_dic[r[0]] = r[2]
    same = True
    keys = list(file_dic.keys())
    while True:
        try:
            key = random.choice(keys)
            value = random.choice(file_dic.get(key))
            path = os.path.join(key, value)
            key_ = random.choice(keys)
            value_ = random.choice(file_dic.get(key_))
            path_ = os.path.join(key_, value_)
            # print(path, path_)
            if key_ == key:
                label = 0.0
            else:
                label = 1.0
            yield path, path_, label
        except:
            pass
```

In the example above, the images are totally randomly selected (Which is not a proper way to train siamese net because this method is likely to give negative image pairs all almost all the time), but it does indicates how is the streamer supposed to work. 

It firstly list all the possible file paths by doing a directory tree walk, then yeild three things: two image paths and whether they belongs to the same person.

However, this is not enough because we have to load the actual iamge data from the hard disk, so we have to map the dataset to a new one as following:

```python

def _parse_function(path, path_, label):
  image_string = tf.read_file(path)
  image_string_ = tf.read_file(path_)
  image_decoded = tf.image.decode_jpeg(image_string)
  image_decoded_ = tf.image.decode_jpeg(image_string_)
  image_decoded = tf.image.rgb_to_grayscale(image_decoded)
  image_decoded_ = tf.image.rgb_to_grayscale(image_decoded_)

  image_resized = tf.image.per_image_standardization(tf.image.resize_images(image_decoded, [128, 128]))
  image_resized_ = tf.image.per_image_standardization(tf.image.resize_images(image_decoded_, [128, 128]))


  out = tf.concat([tf.reshape(image_resized, [16384,]), tf.reshape(image_resized_, [16384,])],axis=-1)

  return out, label


def input_func_gen():
    dset = tf.data.Dataset.from_generator(
        generator,
        output_types=(tf.string, tf.string, tf.float32)
    )

    dset = dset.map(map_func=_parse_function,num_parallel_calls=4)



    return dset
```

In the code above, the Dataset instance is firstly instanciated using from_generator method, followed by a mapping method. The parse function is used to map path to the actual image. The parse function accepts the parameters which are exact same as data yielded fro mthe streamer, and return the data of image. The data is the feature parameter of model function.

